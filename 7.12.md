
- ***Selection Bias:*** the treatment is correlated with other characteristics that can influence outcome.
- ***Omitted Variable Bias (OVB):*** are omitted variables are correlated with included explanatory 
- ***Data Generating Process:***
	$y_i = ß_0 + ß_1 x_1i + ß_2 X_2i + ...+ Error_1$
- Example: RCT
	$y_i = ß_0 + ß_1D_i + Error_i$
- Linear Fit
	$y_i = ß_0 + ß_1 x_1i + ß_2 X_2i + ...+ ß_jx_ji$
	- $y_i(observed) - y_i = Error_i(residual)$
	- OLS estimator = avg min $∑^n_iError_i^2$
	- {${ß_0, ß_1, ..., ß_j}$}
- Assumptions for OLS
	- $E(Error_i) = 0$
	- $Cov(x_ji, Error_i) = 0$
	- Error must be independent of covariants
	- $Var(Error_i) = Var(Error_i | x)$ Homoskodastic Correlation
 - $ATE = Avg(y_i | D_i = 1) - Avg(y_i | D_i = 0)$

***Endogeneity Simultaneity***
![](https://hackmd.io/_uploads/ry2rgZiK2.png)



$R^2 = 1- \frac{RSS}{TSS} = 1 - \frac{\sum^n_i \hat{Error}^2}{\sum^n_i (y_i - \bar{y})^2}$
- $Error^n, or residual, is the unexplained part of y_i$
- $y_i - \bar{y}$ is the total variation in y
- $R^2$ = % of explained variations
- if you are using a predicted model, you want $R^2$ to be high. But, if it is too high, we will encounter ***overfitting***

